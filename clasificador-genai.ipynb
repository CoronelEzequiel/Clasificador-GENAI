{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d387800",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-generativeai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === CONFIGURACI√ìN ===\n",
    "CARPETA_ENTRADA = \"textos\"\n",
    "CARPETA_SALIDA = \"resultados\"\n",
    "ARCHIVO_LOG = \"log_errores.txt\"\n",
    "\n",
    "# Inicializar modelo\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Or use `os.getenv('GEMINI_API_KEY')` to fetch an environment variable.\n",
    "#GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
    "#GEMINI_API_KEY = 'un-api-valido'\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "#model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "#model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "#model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "#model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "\n",
    "# Inicializar modelo con par√°metros ajustados para mejorar precisi√≥n y robustez\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-lite\",\n",
    "    generation_config={\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"candidate_count\": 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ad57ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que exista la carpeta de salida\n",
    "os.makedirs(CARPETA_SALIDA, exist_ok=True)\n",
    "\n",
    "# Inicializar archivo de log\n",
    "with open(ARCHIVO_LOG, \"w\", encoding=\"utf-8\") as log:\n",
    "    log.write(\"=== LOG DE ERRORES ===\\n\")\n",
    "\n",
    "# Archivos de entrada\n",
    "archivos_txt = [f for f in os.listdir(CARPETA_ENTRADA) if f.endswith(\".txt\")]\n",
    "\n",
    "# Token acumulado\n",
    "total_tokens_global = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d8c4824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Procesado: #25demayoenradio10 - banda militar en el centro cultural kirchner.txt | Tokens: 546\n",
      "‚úÖ Procesado: #25demayoenradio10 - jorge capitanich mano a mano con jorge rial.txt | Tokens: 2999\n",
      "‚úÖ Procesado: #25demayoenradio10 - los pampas en el centro cultural kirchner.txt | Tokens: 925\n",
      "‚úÖ Procesado: #25demayoenradio10 - mart√≠n bonavetti con gustavo sylvestre y jorge rial.txt | Tokens: 1098\n",
      "‚úÖ Procesado: #25demayoenradio10 - trist√°n bauer, ministro de cultura, mano a mano con jorge rial.txt | Tokens: 1403\n",
      "‚úÖ Procesado: #argenzuela -  audios exclusivos de la entrevista de jey mammon con rial.txt | Tokens: 3167\n",
      "‚úÖ Procesado: #argenzuela -  diego giuliano, ministro de transporte de la naci√≥n.txt | Tokens: 1378\n",
      "‚úÖ Procesado: #argenzuela -  federico fagioli, senador bonaerense, referente del patria grande.txt | Tokens: 2232\n",
      "‚úÖ Procesado: #argenzuela -  miguel angel pichetto sobre el asado en olivos y el festejo pol√≠tico de javier milei.txt | Tokens: 2372\n",
      "‚úÖ Procesado: #argenzuela -  ra√∫l jalil le respondi√≥ a larreta.txt | Tokens: 1559\n",
      "\n",
      "üß† Total global de tokens procesados: 17679\n"
     ]
    }
   ],
   "source": [
    "# Procesamiento\n",
    "for archivo in archivos_txt:\n",
    "    ruta_entrada = os.path.join(CARPETA_ENTRADA, archivo)\n",
    "    ruta_salida = os.path.join(CARPETA_SALIDA, f\"{os.path.splitext(archivo)[0]}.json\")\n",
    "\n",
    "    with open(ruta_entrada, \"r\", encoding=\"utf-8\") as f:\n",
    "        texto = f.read()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Clasific√° el siguiente texto seg√∫n su orientaci√≥n pol√≠tica en Argentina como 'izquierda', \n",
    "    'derecha' o 'neutral' en ultima instancia, la prioridad es derecha o izquierda, pero si es muy incierto entonces se dice neutral. Para el campo 'texto_id' us√° el nombre\n",
    "    del archivo sin extensi√≥n. \n",
    "    Devolv√© la respuesta en formato JSON con las siguientes claves:\n",
    "\n",
    "    - \\\"texto_id\\\": nombre identificador (us√° el nombre del archivo sin extensi√≥n)\n",
    "    - \\\"clasificacion\\\": 'izquierda', 'derecha' o 'neutral'\n",
    "    - \\\"confianza\\\": alta, media o baja\n",
    "    - \\\"motivos\\\": lista de 3 a 5 razones\n",
    "    - \\\"entidades_mencionadas\\\": lista con nombres propios pol√≠ticos o de figuras p√∫blicas \n",
    "    mencionadas\n",
    "\n",
    "    Texto:\n",
    "    \\\"\\\"\\\"\n",
    "    {texto}\n",
    "    \\\"\\\"\\\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        raw = response.text.strip()\n",
    "        if raw.startswith(\"```json\"):\n",
    "            raw = raw.removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "\n",
    "        total_tokens = None\n",
    "        if hasattr(response, \"usage_metadata\") and response.usage_metadata:\n",
    "            total_tokens = response.usage_metadata.total_token_count\n",
    "            total_tokens_global += total_tokens or 0\n",
    "\n",
    "        resultado = json.loads(raw)\n",
    "\n",
    "        if \"texto_id\" not in resultado:\n",
    "            resultado[\"texto_id\"] = os.path.splitext(archivo)[0]\n",
    "\n",
    "        resultado[\"tokens_procesados\"] = total_tokens\n",
    "\n",
    "    except Exception as e:\n",
    "        resultado = {\n",
    "            \"texto_id\": os.path.splitext(archivo)[0],\n",
    "            \"error\": str(e),\n",
    "            \"raw_response\": getattr(response, \"text\", \"Sin respuesta\"),\n",
    "            \"tokens_procesados\": None\n",
    "        }\n",
    "        with open(ARCHIVO_LOG, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(f\"‚ùå Error en {archivo}: {str(e)}\\n\")\n",
    "\n",
    "    with open(ruta_salida, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Procesado: {archivo} | Tokens: {resultado.get('tokens_procesados', 'N/A')}\")\n",
    "\n",
    "# Mostrar total de tokens usados\n",
    "print(f\"\\nüß† Total global de tokens procesados: {total_tokens_global}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
